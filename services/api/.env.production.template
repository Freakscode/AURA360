# ==============================================================================
# AURA360 - Configuración de Producción para GCP Cloud Run
# ==============================================================================
# Este archivo contiene todas las variables de entorno necesarias para desplegar
# la API Django y el Worker de Celery en Google Cloud Run.
#
# INSTRUCCIONES:
# 1. Copia este archivo a .env.production:
#    cp .env.production.template .env.production
#
# 2. Reemplaza todos los valores marcados con <...> con tus credenciales reales
#
# 3. Valida la configuración con:
#    ./scripts/validate_production_env.sh services/api/.env.production
#
# 4. Despliega con:
#    export API_ENV_FILE="services/api/.env.production"
#    export WORKER_ENV_FILE="services/api/.env.production"
#    ./deploy_all_gcloud.sh
#
# IMPORTANTE:
# - El archivo .env.production NO debe ser commiteado a Git (ya está en .gitignore)
# - Guarda este template para referencia futura
# ==============================================================================

# ==============================================================================
# DJANGO CORE CONFIGURATION
# ==============================================================================

# Secret Key de Django - Genera uno nuevo para producción:
# python -c 'from django.core.management.utils import get_random_secret_key; print(get_random_secret_key())'
SECRET_KEY=<GENERA_UNA_SECRET_KEY_SEGURA>

# Debug mode - SIEMPRE False en producción
DEBUG=False

# Hosts permitidos - Actualiza después del primer deploy con la URL de Cloud Run
# Formato: dominio1.com,dominio2.com (sin espacios)
# Ejemplo temporal: *.run.app (permitirá cualquier servicio de Cloud Run)
ALLOWED_HOSTS=*.run.app

# ==============================================================================
# DATABASE CONFIGURATION (Supabase PostgreSQL)
# ==============================================================================

# Engine de base de datos (no cambiar)
DB_ENGINE=django.db.backends.postgresql

# Nombre de la base de datos
DB_NAME=postgres

# Usuario de la base de datos (formato: postgres.PROJECT_REF)
# Obtener desde: Supabase Dashboard > Settings > Database > Connection string > Connection pooling
DB_USER=postgres.<TU_PROJECT_REF>

# Password de la base de datos
# Obtener desde: Supabase Dashboard > Settings > Database > Reset database password
DB_PASSWORD=<TU_DB_PASSWORD>

# Host de Supabase (usar pooler para producción)
# Formato: aws-0-REGION.pooler.supabase.com
# Obtener desde: Supabase Dashboard > Settings > Database > Connection string > Connection pooling
DB_HOST=aws-0-us-east-1.pooler.supabase.com

# Puerto del pooler de Supabase (6543 para pooling, 5432 para conexión directa)
DB_PORT=6543

# Connection pooling - 600 segundos para producción (10 minutos)
CONN_MAX_AGE=600

# ==============================================================================
# SUPABASE CONFIGURATION
# ==============================================================================

# URL base de tu proyecto Supabase
# Formato: https://TU_PROJECT_REF.supabase.co
# Obtener desde: Supabase Dashboard > Settings > API > Project URL
SUPABASE_URL=https://<TU_PROJECT_REF>.supabase.co

# API URL de Supabase (generalmente igual a SUPABASE_URL)
SUPABASE_API_URL=https://<TU_PROJECT_REF>.supabase.co

# Service Role Key (SECRETO - NO EXPONER AL FRONTEND)
# Obtener desde: Supabase Dashboard > Settings > API > service_role key
SUPABASE_SERVICE_ROLE_KEY=<TU_SERVICE_ROLE_KEY>

# JWKS URL para validar tokens JWT de Supabase
# Formato: https://TU_PROJECT_REF.supabase.co/auth/v1/.well-known/jwks.json
SUPABASE_JWKS_URL=https://<TU_PROJECT_REF>.supabase.co/auth/v1/.well-known/jwks.json

# JWT Secret (opcional, para fallback HS256)
# Obtener desde: Supabase Dashboard > Settings > API > JWT Secret
SUPABASE_JWT_SECRET=<TU_JWT_SECRET>

# Timeout para llamadas a la API de Supabase (segundos)
SUPABASE_ADMIN_TIMEOUT=10

# ==============================================================================
# KAFKA / CONFLUENT CLOUD CONFIGURATION
# ==============================================================================

# Bootstrap servers de Kafka (Confluent Cloud)
# Obtener desde: Confluent Cloud > Cluster > Settings > Bootstrap server
# Formato: pkc-xxxxx.REGION.aws.confluent.cloud:9092
KAFKA_BOOTSTRAP_SERVERS=<pkc-xxxxx.us-east-1.aws.confluent.cloud:9092>

# API Key de Confluent Cloud
# Crear desde: Confluent Cloud > API Keys > Add Key > Cluster-specific
KAFKA_API_KEY=<TU_KAFKA_API_KEY>

# API Secret de Confluent Cloud (SECRETO - guardar inmediatamente al crear)
# ⚠️ IMPORTANTE: Guarda este valor inmediatamente, no podrás verlo después
KAFKA_API_SECRET=<TU_KAFKA_API_SECRET>

# Schema Registry URL (opcional, solo si usas Schema Registry)
# Formato: https://psrc-xxxxx.REGION.aws.confluent.cloud
# KAFKA_SCHEMA_REGISTRY_URL=https://psrc-xxxxx.us-east-1.aws.confluent.cloud

# ==============================================================================
# CELERY / REDIS CONFIGURATION
# ==============================================================================

# URL del broker de Redis para Celery
# Opciones:
# - Upstash Redis: rediss://default:PASSWORD@HOST:6379/0
# - MemoryStore (GCP): redis://HOST:6379/0 (requiere VPC connector)
# Formato: redis://[password@]host:port/db_number
# Para Upstash con TLS: rediss://default:PASSWORD@HOST:6379/0
CELERY_BROKER_URL=rediss://default:<PASSWORD>@<redis-host>:6379/0

# Result backend de Celery (generalmente igual al broker, pero diferente DB)
CELERY_RESULT_BACKEND=rediss://default:<PASSWORD>@<redis-host>:6379/1

# Timeout para tareas de Celery (segundos)
CELERY_TASK_TIME_LIMIT=600
CELERY_TASK_SOFT_TIME_LIMIT=540

# Cola por defecto
CELERY_TASK_DEFAULT_QUEUE=api_default

# ==============================================================================
# EXTERNAL SERVICES CONFIGURATION
# ==============================================================================

# URL base del servicio de base de datos vectorial
# Actualizar después del deploy de vectordb service
# Formato: https://vectordb-service-HASH-REGION.run.app
# Ejemplo temporal: https://vectordb-xxxxx-uc.a.run.app
VECTOR_DB_BASE_URL=https://<vectordb-service-url>

# URL del servicio de agentes holísticos
# Actualizar después del deploy de agents service
# Formato: https://agents-service-HASH-REGION.run.app/api/holistic/v1/run
# Ejemplo temporal: https://agents-xxxxx-uc.a.run.app/api/holistic/v1/run
HOLISTIC_AGENT_SERVICE_URL=https://<agents-service-url>/api/holistic/v1/run

# Token de autenticación para el servicio de agentes (opcional)
# HOLISTIC_AGENT_SERVICE_TOKEN=<token>

# Timeout para requests al servicio de agentes (segundos)
HOLISTIC_AGENT_REQUEST_TIMEOUT=120

# URL del servicio de reportes holísticos (opcional)
# HOLISTIC_REPORT_SERVICE_URL=https://<reports-service-url>/render
# HOLISTIC_REPORT_SERVICE_TOKEN=<token>

# ==============================================================================
# CORS CONFIGURATION
# ==============================================================================

# Orígenes permitidos para CORS
# Actualizar después del deploy del frontend
# Formato: https://dominio1.com,https://dominio2.com (sin espacios)
# Incluir también Cloud Storage si sirves el frontend desde ahí
CORS_ALLOWED_ORIGINS=https://storage.googleapis.com

# ==============================================================================
# NUTRITION PLAN INGESTION (Opcional)
# ==============================================================================

# URL del servicio de ingestión de planes nutricionales
# NUTRITION_PLAN_INGESTION_URL=https://<ingestion-service-url>/ingest
# NUTRITION_PLAN_INGESTION_TOKEN=<token>

# Bucket de Supabase Storage para planes nutricionales
# NUTRITION_PLAN_STORAGE_BUCKET=nutrition-plans
# NUTRITION_PLAN_STORAGE_PREFIX=nutrition-plans
# NUTRITION_PLAN_STORAGE_PUBLIC_URL=https://<tu-proyecto>.supabase.co/storage/v1/object/public/nutrition-plans

# ==============================================================================
# INSTRUCCIONES POST-DEPLOY
# ==============================================================================
#
# PASO 1: Configurar credenciales básicas
#   - SECRET_KEY: Generar con el comando Python indicado arriba
#   - DB_*: Obtener desde Supabase Dashboard > Settings > Database
#   - SUPABASE_*: Obtener desde Supabase Dashboard > Settings > API
#   - KAFKA_*: Obtener desde Confluent Cloud > Cluster > Settings y API Keys
#   - CELERY_BROKER_URL: Configurar Redis (Upstash o MemoryStore)
#
# PASO 2: Primer deploy del API
#   export API_ENV_FILE="services/api/.env.production"
#   export WORKER_ENV_FILE="services/api/.env.production"
#   ./deploy_all_gcloud.sh
#
# PASO 3: Actualizar URLs después del deploy
#   - Obtener la URL del API desde Cloud Run Console
#   - Actualizar ALLOWED_HOSTS con la URL específica (ej: aura360-api-xxxxx-uc.a.run.app)
#   - Actualizar CORS_ALLOWED_ORIGINS con la URL del frontend
#
# PASO 4: Desplegar servicios externos y actualizar
#   - Desplegar vectordb service y actualizar VECTOR_DB_BASE_URL
#   - Desplegar agents service y actualizar HOLISTIC_AGENT_SERVICE_URL
#
# PASO 5: Validar configuración
#   ./services/api/scripts/validate_production_env.sh services/api/.env.production
#
# PASO 6: Re-desplegar con configuración completa
#   ./deploy_all_gcloud.sh
#
# ==============================================================================
