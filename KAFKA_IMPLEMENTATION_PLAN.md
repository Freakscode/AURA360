# AURA360 - Plan de ImplementaciÃ³n: Event-Driven Architecture con Confluent

**Fecha**: 2025-01-07
**Timeline**: 1-2 semanas
**Complejidad**: Full Event-Driven
**Equipo**: Backend Dev (Python/Django), DevOps, Frontend/Mobile Dev
**Experiencia con Kafka**: Ninguna

---

## ğŸ“‹ Executive Summary

AURA360 migrarÃ¡ de arquitectura basada en HTTP sÃ­ncrono + Celery a **Event-Driven Architecture** usando **Apache Kafka (Confluent Cloud)**. Esto mejorarÃ¡:

- âœ… **Decoupling**: Servicios independientes sin conocimiento mutuo
- âœ… **Resilencia**: Si un servicio cae, eventos se retienen y procesan despuÃ©s
- âœ… **Escalabilidad**: FÃ¡cil agregar consumers para procesar mÃ¡s carga
- âœ… **Extensibilidad**: Nuevas features = nuevos consumers, sin tocar cÃ³digo existente

**Beneficio del perk**: 1 aÃ±o gratis de Confluent Cloud (valor ~$13,200 USD).

---

## ğŸ—ï¸ Arquitectura Propuesta

### Antes (HTTP SÃ­ncrono)

```
Mobile App
    â†“ HTTP POST
Django API â†’ (espera) â†’ Agents Service
    â†“ HTTP POST
Django API â†’ (espera) â†’ Vectordb Service
    â†“
Celery Task â†’ Redis â†’ Worker â†’ Qdrant
```

**Problemas**:
- Tight coupling (Django conoce a todos los servicios)
- Si Vectordb cae, Django devuelve error al usuario
- DifÃ­cil agregar nuevos consumers (ej: analytics, notifications)

### DespuÃ©s (Event-Driven)

```
Mobile App
    â†“ HTTP POST
Django API
    â†“ publish event
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    KAFKA (Confluent Cloud)                  â”‚
â”‚                                                             â”‚
â”‚  Topics:                                                    â”‚
â”‚   - aura360.user.events                                     â”‚
â”‚   - aura360.context.aggregated                              â”‚
â”‚   - aura360.context.vectorized                              â”‚
â”‚   - aura360.guardian.requests                               â”‚
â”‚   - aura360.guardian.responses                              â”‚
â”‚   - aura360.vectordb.ingest                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚                    â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚Context  â”‚         â”‚  Guardian â”‚       â”‚ Vectordb  â”‚
    â”‚Aggreg.  â”‚         â”‚  Consumer â”‚       â”‚ Consumer  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ventajas**:
- Django solo publica evento y retorna 201 inmediatamente
- Consumers procesan en paralelo
- Agregar analytics/notifications = agregar consumer nuevo
- Si Vectordb cae, Kafka retiene eventos para replay

---

## ğŸ“… Timeline Detallado (14 dÃ­as)

| DÃ­as | Fase | Responsable | Entregables |
|------|------|-------------|-------------|
| 1-3 | Setup & Fundamentos | DevOps + Backend | docker-compose.dev.yml, mÃ³dulo shared/messaging, POCs |
| 4-6 | Django API Event Publishing | Backend Django | Views publicando eventos en lugar de HTTP calls |
| 4-7 | Vectordb Event Consumption | Backend FastAPI | Consumers procesando context aggregation/vectorization |
| 7-9 | Agents Guardian Communication | Backend Agents | Request-reply pattern para Guardian advice |
| 8-10 | Mobile/Frontend Integration | Frontend/Mobile | WebSocket streaming de respuestas |
| 10-14 | DevOps Deployment | DevOps | Deploy a Railway, monitoring, runbooks |
| 12-14 | Testing & Validation | Todo el equipo | E2E tests, load testing, bug fixing |

---

## ğŸ‘¥ Roles y Responsabilidades

### **DevOps Lead** ğŸ”§

**DÃ­as 1-3:**
- [ ] Activar Confluent Cloud (1 aÃ±o gratis)
- [ ] Crear cluster en us-east-1 (Basic tier)
- [ ] Crear 6 topics con retention 7 dÃ­as
- [ ] Obtener API Keys + Bootstrap URL
- [ ] **Setup Confluent MCP Server** (15 min):
  - [ ] Instalar Node.js 22
  - [ ] Crear `.env` con credenciales Confluent
  - [ ] Configurar Claude Desktop con MCP
  - [ ] Verificar: "Claude, lista todos los topics"
- [ ] Crear docker-compose.dev.yml con Kafka local
- [ ] Configurar Kafka UI para debugging

**DÃ­as 10-14:**
- [ ] Crear Dockerfiles para nuevos consumers
- [ ] Setup Confluent Cloud para producciÃ³n (ACLs, monitoring)
- [ ] Actualizar DEPLOYMENT.md
- [ ] Configurar secrets en Railway
- [ ] Deploy staging â†’ smoke tests â†’ production
- [ ] Setup alerting (Confluent + Railway)

**Entregables:**
1. Confluent Cloud configurado
2. docker-compose.dev.yml funcional
3. Secrets en Railway
4. DEPLOYMENT.md actualizado
5. Monitoring dashboard

---

### **Backend Developer (Django)** ğŸ

**DÃ­as 1-3:**
- [ ] Estudiar Confluent fundamentals (2h curso gratis)
- [ ] Crear mÃ³dulo `services/shared/messaging/`
  - `kafka_producer.py`
  - `kafka_consumer.py`
  - `events.py` (schemas)
  - `config.py`
- [ ] POC: "Hello Kafka" (publisher â†’ consumer local)
- [ ] Tests unitarios para producer/consumer

**DÃ­as 4-6:**
- [ ] Refactorizar `services/api/holistic/context_aggregator.py`
- [ ] Modificar views para publicar eventos:
  - `POST /api/holistic/mood-entries/` â†’ publish `user.mood.created`
  - `POST /api/holistic/activities/` â†’ publish `user.activity.created`
  - `POST /api/holistic/ikigai/` â†’ publish `user.ikigai.updated`
- [ ] Implementar event publisher en `holistic/kafka_publisher.py`
- [ ] Agregar idempotency keys
- [ ] Tests de integraciÃ³n

**Entregables:**
1. MÃ³dulo shared/messaging reutilizable
2. Django API publicando eventos
3. Tests (80%+ coverage)
4. DocumentaciÃ³n de schemas

---

### **Backend Developer (Vectordb FastAPI)** ğŸš€

**DÃ­as 4-7:**
- [ ] Crear `services/vectordb/vectosvc/kafka/`
  - `consumer.py`
  - `handlers.py`
- [ ] Implementar `ContextAggregationHandler`
  - Consume: `user.mood.created`
  - Publica: `context.aggregated`
- [ ] Implementar `ContextVectorizationHandler`
  - Consume: `context.aggregated`
  - Publica: `context.vectorized`
- [ ] Implementar `VectordbIngestHandler`
  - Consume: `context.vectorized`
  - Inserta en Qdrant
- [ ] Crear Dockerfile.consumer
- [ ] Migrar Celery tasks actuales a Kafka (mantener Celery solo para batch PDF processing)
- [ ] Tests end-to-end: Mood entry â†’ Qdrant

**Entregables:**
1. Consumers funcionando localmente
2. Pipeline completo: User event â†’ Context â†’ Vectors â†’ Qdrant
3. Tests E2E
4. Dockerfile.consumer

---

### **Backend Developer (Agents Service)** ğŸ§ 

**DÃ­as 7-9:**
- [ ] Crear `services/agents/kafka/consumer.py`
- [ ] Implementar `GuardianRequestHandler`
  - Consume: `guardian.requests`
  - Ejecuta Guardian agent
  - Publica: `guardian.responses`
- [ ] Refactorizar `services/holistic.py` para usar Kafka
  - Request-reply pattern con correlation ID
- [ ] Implementar timeout handling (30s)
- [ ] (Opcional) Implementar streaming responses:
  - Guardian emite chunks a `guardian.response.chunks`
  - Django consume y pushea via WebSocket
- [ ] Tests: Request advice â†’ response en Kafka

**Entregables:**
1. Guardian consumer funcionando
2. Request-reply pattern implementado
3. (Opcional) Streaming responses
4. Tests de integraciÃ³n

---

### **Frontend/Mobile Developer** ğŸ“±

**DÃ­as 8-10:**
- [ ] Actualizar Flutter app para WebSocket connection a Django
- [ ] Implementar UI que muestre respuestas progresivas de Guardians
- [ ] Agregar indicadores de estado (procesando, vectorizando, etc.)
- [ ] (Si aplica) Actualizar Angular app
- [ ] Tests E2E desde UI: Create mood â†’ ver proceso â†’ recibir advice
- [ ] Polish UX: loading states, error handling
- [ ] Testing en dispositivos reales

**Entregables:**
1. Flutter app con WebSocket streaming
2. UI con estados de procesamiento
3. Error handling robusto
4. Tests E2E desde UI

---

## ğŸ“Š MÃ©tricas de Ã‰xito

### KPIs TÃ©cnicos

| MÃ©trica | Target | Herramienta |
|---------|--------|-------------|
| Latencia end-to-end | <5 segundos | Confluent Cloud Metrics |
| Consumer lag | <100ms promedio | Confluent Cloud Dashboard |
| Event delivery rate | 100% (0 pÃ©rdidas) | Kafka delivery reports |
| Test coverage | >80% | pytest --cov |
| Uptime | >99.5% | Railway + Confluent monitoring |

### KPIs de Negocio

- âœ… 0 llamadas HTTP sÃ­ncronas entre servicios
- âœ… Capacidad de agregar features sin modificar cÃ³digo existente
- âœ… Rollback plan funcional en caso de problemas
- âœ… DocumentaciÃ³n completa para onboarding

---

## âš ï¸ Riesgos y Mitigaciones

### Riesgo 1: Equipo sin experiencia en Kafka (ALTO)

**Impacto**: Errores de implementaciÃ³n, timeline alargado

**MitigaciÃ³n**:
- âœ… DÃ­a 1: Todo el equipo completa Confluent Academy (4h curso gratis)
- âœ… DevOps hace POC primero, luego enseÃ±a al equipo en daily standups
- âœ… Usar abstracciones del mÃ³dulo shared/messaging (simplifica API)
- âœ… Code reviews exhaustivos por alguien con experiencia en event-driven

### Riesgo 2: Bugs en producciÃ³n por complejidad event-driven (MEDIO)

**Impacto**: Downtime, pÃ©rdida de eventos, UX degradada

**MitigaciÃ³n**:
- âœ… Deploy gradual: 1% â†’ 10% â†’ 50% â†’ 100% trÃ¡fico
- âœ… Feature flag para rollback a Celery si algo falla
- âœ… Monitoring desde dÃ­a 1 (Confluent + Railway alerts)
- âœ… Runbooks para troubleshooting comÃºn

### Riesgo 3: Consumer lag en producciÃ³n (MEDIO)

**Impacto**: Latencia alta percibida por usuarios

**MitigaciÃ³n**:
- âœ… Load testing antes de producciÃ³n (simular 100 usuarios concurrentes)
- âœ… Auto-scaling de consumers en Railway (configurar desde inicio)
- âœ… Alertas en Confluent Cloud si lag > 1000 mensajes
- âœ… Optimization checklist: partitions, consumer concurrency, batch sizes

### Riesgo 4: Timeline agresivo (1-2 semanas) (ALTO)

**Impacto**: No se completa implementaciÃ³n, deployment incompleto

**MitigaciÃ³n**:
- âœ… Checkpoint GO/NO-GO en dÃ­a 7:
  - Si POC funciona â†’ continuar
  - Si no funciona â†’ pivotear a implementaciÃ³n Balanced (mantener mÃ¡s Celery)
- âœ… Priorizar features: CDC + User Events (MUST) > Guardian Streaming (NICE)
- âœ… Daily standups de 15 min para identificar blockers temprano
- âœ… Tener a alguien disponible full-time (no part-time entre proyectos)

---

## ğŸš¦ Checkpoint GO/NO-GO (DÃ­a 7)

### Criterios GO

- [ ] POC funciona localmente (publisher â†’ consumer)
- [ ] Equipo entiende conceptos bÃ¡sicos (topics, partitions, consumer groups)
- [ ] Django publica eventos correctamente
- [ ] Vectordb consume eventos correctamente
- [ ] 0 blockers crÃ­ticos identificados
- [ ] Timeline tracking on schedule

### Criterios NO-GO

Si falla alguno de los anteriores:

**Plan B**: Pivotear a implementaciÃ³n **Balanced**:
- Mantener HTTP calls para Guardian requests (crÃ­tico para UX)
- Solo migrar context aggregation a Kafka
- Reducir scope para cumplir timeline

---

## ğŸ“š Recursos de Aprendizaje

### DÃ­a 1 - TODO EL EQUIPO (4 horas)

**Obligatorio**:
1. [Confluent Fundamentals](https://developer.confluent.io/courses/apache-kafka/events/) (2h)
2. [Event-Driven Architecture 101](https://www.confluent.io/learn/event-driven-architecture/) (1h)
3. Leer `services/shared/README.md` (30 min)
4. Ejecutar QUICKSTART_KAFKA.md (30 min)

**Opcional**:
- [Kafka Patterns](https://developer.confluent.io/patterns/) (1h)
- [Request-Reply Pattern](https://www.confluent.io/blog/request-reply-pattern-apache-kafka/) (30 min)

### Referencias RÃ¡pidas

- **MÃ³dulo shared**: `services/shared/README.md`
- **Quickstart**: `QUICKSTART_KAFKA.md`
- **Deployment**: `DEPLOYMENT.md` (secciÃ³n Confluent)
- **Event Schemas**: `services/shared/messaging/events.py`
- **MCP Setup**: `MCP_CONFLUENT_SETUP.md` â­ NUEVO
- **Confluent Docs**: https://docs.confluent.io/kafka-clients/python/current/
- **Kafka UI Local**: http://localhost:8090
- **Claude Desktop con MCP**: GestiÃ³n conversacional de Kafka

---

## ğŸ”„ Workflow Diario Recomendado

### Daily Standup (15 min, 9:00 AM)

**Agenda**:
1. Cada rol reporta: Â¿QuÃ© hice ayer? Â¿QuÃ© harÃ© hoy? Â¿AlgÃºn blocker?
2. DevOps Lead actualiza timeline tracker (Â¿vamos on track?)
3. Resolver blockers crÃ­ticos o escalar

### Code Review Policy

**Obligatorio para**:
- Todos los cambios en `services/shared/messaging/`
- Implementaciones de consumers
- Cambios en event schemas

**Revisor**: Alguien con experiencia en event-driven o DevOps Lead

### Testing antes de Merge

**Checklist**:
- [ ] Unit tests pasan (`pytest`)
- [ ] Integration test manual (publisher â†’ consumer local)
- [ ] Verificado en Kafka UI (mensaje visible en topic)
- [ ] Code review aprobado
- [ ] No rompe build de otros servicios

---

## ğŸ“¦ Entregables Finales

### CÃ³digo

1. âœ… `services/shared/messaging/` - MÃ³dulo compartido
2. âœ… `docker-compose.dev.yml` - Infra local con Kafka
3. âœ… Django API publicando eventos
4. âœ… Vectordb consumers procesando eventos
5. âœ… Agents consumers para Guardian requests
6. âœ… (Opcional) Flutter WebSocket streaming

### DocumentaciÃ³n

1. âœ… `KAFKA_IMPLEMENTATION_PLAN.md` (este documento)
2. âœ… `QUICKSTART_KAFKA.md` - GuÃ­a de inicio rÃ¡pido
3. âœ… `services/shared/README.md` - Docs del mÃ³dulo messaging
4. âœ… `DEPLOYMENT.md` actualizado con secciÃ³n Confluent
5. âœ… Runbooks de troubleshooting

### Infraestructura

1. âœ… Confluent Cloud configurado (producciÃ³n)
2. âœ… Kafka local en Docker (desarrollo)
3. âœ… Secrets configurados en Railway
4. âœ… Monitoring dashboard (Confluent + Railway)
5. âœ… Alertas configuradas (consumer lag, errors)

---

## ğŸ¯ Siguiente AcciÃ³n Inmediata

**Para empezar AHORA**:

1. **DevOps**: Activar cuenta Confluent Cloud (5 min)
   ```
   https://confluent.cloud â†’ Sign Up â†’ Activar perk 1 aÃ±o gratis
   ```

2. **Backend Devs**: Levantar Kafka local (5 min)
   ```bash
   cd /path/to/AURA360
   docker-compose -f docker-compose.dev.yml up -d
   open http://localhost:8090  # Verificar Kafka UI
   ```

3. **TODO EL EQUIPO**: Completar learning resources (4h)
   ```
   Confluent Fundamentals â†’ Event-Driven Architecture 101 â†’ QUICKSTART_KAFKA.md
   ```

4. **Daily Standups**: Schedule diario de 15 min (9:00 AM)

---

## ğŸ’° Costos Post AÃ±o-Gratis

### OpciÃ³n 1: Self-Host Kafka en Railway
- **Costo**: ~$150-300/mes
- **Pros**: Control total, mÃ¡s barato que Confluent paid
- **Contras**: Overhead operacional, pierdes features managed

### OpciÃ³n 2: Confluent Cloud Paid
- **Costo**: ~$1,100/mes (Standard tier)
- **Pros**: Fully managed, auto-scaling, soporte 24/7
- **Contras**: Costoso si revenue < $10K/mes

### OpciÃ³n 3: Hybrid (Recomendado)
- **Costo**: ~$300/mes
- **Stack**: Self-hosted Kafka para eventos crÃ­ticos + Celery para batch jobs
- **Pros**: Balance costo/features
- **Contras**: Complejidad de mantener ambos

**DecisiÃ³n en Mes 10**: Evaluar revenue y escala antes de que expire el aÃ±o gratis.

---

## âœ… Checklist Final Pre-Deployment

Antes de deploy a producciÃ³n, verificar:

- [ ] Todos los tests E2E pasan (mÃ³vil â†’ Django â†’ Kafka â†’ Vectordb â†’ Qdrant)
- [ ] Load test con 100 usuarios simulados exitoso (consumer lag <500ms)
- [ ] Confluent Cloud configurado con topics + ACLs correctos
- [ ] Secrets de Confluent en Railway (API Key, Bootstrap URL)
- [ ] Monitoring dashboard funcional (Confluent + Railway)
- [ ] Alertas configuradas (consumer lag >1000, error rate >1%)
- [ ] Runbooks documentados (troubleshooting comÃºn)
- [ ] Rollback plan probado (feature flag para volver a Celery)
- [ ] Code review completo (por alguien con experiencia event-driven)
- [ ] DocumentaciÃ³n actualizada (DEPLOYMENT.md, README.md, CLAUDE.md)
- [ ] Onboarding docs para futuros devs
- [ ] Backup de configuraciÃ³n (topics, partitions, retention policies)

---

**ğŸš€ Listo para empezar! Siguiente paso: Ver QUICKSTART_KAFKA.md para hands-on.**

---

**Ãšltima actualizaciÃ³n**: 2025-01-07
**VersiÃ³n**: 1.0
**Contacto**: freakscode (Architect/Tech Lead)
