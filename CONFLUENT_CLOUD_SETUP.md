# Confluent Cloud Setup - AURA360

**PropÃ³sito**: GuÃ­a paso a paso para configurar Confluent Cloud para AURA360 con el beneficio de 1 aÃ±o gratis.

**Tiempo estimado**: 30-45 minutos

---

## ðŸ“‹ Pre-requisitos

- âœ… Tarjeta de crÃ©dito (no se cobrarÃ¡ durante el aÃ±o gratis)
- âœ… Email corporativo o personal
- âœ… CÃ³digo de beneficio del perk (si aplica)

---

## ðŸš€ Parte 1: Crear Cuenta en Confluent Cloud

### 1.1 Registro Inicial

1. Ir a https://confluent.cloud
2. Click en **Start Free**
3. Llenar el formulario:
   - **Email**: Tu email corporativo/personal
   - **Password**: ContraseÃ±a segura
   - **First Name / Last Name**
   - **Company**: AURA360 (o tu empresa)
4. Click **Create Account**
5. **Verificar email**: Revisar inbox y click en el link de verificaciÃ³n

### 1.2 Activar Beneficio de 1 AÃ±o Gratis

**OpciÃ³n A: Si tienes cÃ³digo de perk**
1. Login en Confluent Cloud
2. Click en tu perfil (arriba derecha) â†’ **Billing**
3. Click **Apply Promo Code**
4. Ingresar cÃ³digo del perk
5. Click **Apply**
6. âœ… DeberÃ­as ver: "$13,200 promo credit applied (expires in 365 days)"

**OpciÃ³n B: Si usas free trial estÃ¡ndar**
1. Al crear la cuenta, automÃ¡ticamente tienes $400 en crÃ©ditos
2. Suficiente para desarrollo, pero considera el perk para producciÃ³n

---

## ðŸ—ï¸ Parte 2: Crear Cluster de Kafka

### 2.1 Crear Environment

1. En el dashboard principal, click **Environments**
2. Click **+ Add cloud environment**
3. ConfiguraciÃ³n:
   - **Environment name**: `aura360-prod`
   - **Cloud provider**: AWS (recomendado para AURA360)
   - **Region**: us-east-1 (para baja latencia)
4. Click **Create**

### 2.2 Crear Kafka Cluster

1. Dentro del environment `aura360-prod`, click **+ Add cluster**
2. Seleccionar **Basic** cluster:
   - âœ… MÃ¡s barato (~$150/mes sin crÃ©ditos)
   - âœ… Suficiente para 99% de casos de uso
   - âœ… Incluye: durabilidad, auto-scaling, monitoring
3. ConfiguraciÃ³n:
   - **Cluster name**: `aura360-kafka-prod`
   - **Cloud provider**: AWS
   - **Region**: us-east-1 (Virginia)
   - **Availability**: Single Zone (Basic tier)
4. Click **Launch cluster**
5. â³ Esperar 5-10 minutos mientras se aprovisiona

---

## ðŸ“‚ Parte 3: Crear Topics

### 3.1 Topics para AURA360

Una vez que el cluster estÃ© **Ready**, crear los siguientes 6 topics:

#### Topic 1: `aura360.user.events`

1. En el cluster, click **Topics** â†’ **+ Add topic**
2. ConfiguraciÃ³n:
   - **Topic name**: `aura360.user.events`
   - **Partitions**: 3
   - **Retention time**: 7 days (604800000 ms)
   - **Cleanup policy**: delete
   - **Compression type**: snappy (recomendado)
3. Click **Create**

**Repetir para los otros 5 topics**:

#### Topic 2: `aura360.context.aggregated`
- **Partitions**: 3
- **Retention**: 7 days
- **Compression**: snappy

#### Topic 3: `aura360.context.vectorized`
- **Partitions**: 3
- **Retention**: 7 days
- **Compression**: snappy

#### Topic 4: `aura360.guardian.requests`
- **Partitions**: 3
- **Retention**: 7 days
- **Compression**: snappy

#### Topic 5: `aura360.guardian.responses`
- **Partitions**: 3
- **Retention**: 7 days
- **Compression**: snappy

#### Topic 6: `aura360.vectordb.ingest`
- **Partitions**: 3
- **Retention**: 7 days
- **Compression**: snappy

### 3.2 Verificar Topics

1. En **Topics** tab, deberÃ­as ver los 6 topics
2. Click en cada uno para verificar configuraciÃ³n:
   - âœ… Partitions: 3
   - âœ… Replication factor: 3 (automÃ¡tico en Basic tier)
   - âœ… Retention: 604800000 ms (7 dÃ­as)

---

## ðŸ”‘ Parte 4: Generar API Keys

### 4.1 Cluster API Key (para Kafka)

1. En tu cluster `aura360-kafka-prod`, click **API Keys** tab
2. Click **+ Add key**
3. ConfiguraciÃ³n:
   - **Key type**: Cluster-specific
   - **Description**: "AURA360 Production Services"
   - **Scope**: Cluster-specific
4. Click **Create**
5. âš ï¸ **MUY IMPORTANTE**: Copiar y guardar en lugar seguro:
   - **API Key**: Ej. `ABCD1234EFGH5678`
   - **API Secret**: Ej. `xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx`
   - âš ï¸ **NO podrÃ¡s ver el Secret de nuevo**
6. Guardar en 1Password, Bitwarden, o `.env` local (nunca en Git)

### 4.2 Bootstrap Servers

1. En **Cluster settings** (o **Cluster overview**)
2. Buscar secciÃ³n **Bootstrap server**
3. Copiar la URL, deberÃ­a ser algo como:
   ```
   pkc-xxxxx.us-east-1.aws.confluent.cloud:9092
   ```
4. Guardar junto con las API Keys

### 4.3 Cloud API Key (opcional, para MCP Server)

Si vas a usar Claude Desktop con MCP:

1. Click en tu perfil (arriba derecha) â†’ **API Keys**
2. Click **+ Add key**
3. ConfiguraciÃ³n:
   - **Resource type**: Cloud resource management
   - **Scope**: Organization
   - **Description**: "MCP Server for Claude Desktop"
4. Click **Create**
5. Copiar y guardar:
   - **Cloud API Key**
   - **Cloud API Secret**

### 4.4 Schema Registry API Key (opcional)

Si usas Schema Registry:

1. En el environment, click **Schema Registry** tab
2. Click **API Keys** â†’ **+ Add key**
3. ConfiguraciÃ³n:
   - **Description**: "AURA360 Schema Registry"
4. Copiar y guardar keys

---

## ðŸ” Parte 5: Configurar Seguridad (Opcional para ProducciÃ³n)

### 5.1 ACLs (Access Control Lists)

Para producciÃ³n, configura ACLs para limitar permisos:

1. En el cluster, click **Access** tab
2. Click **+ Add ACL**
3. Ejemplo para service account `vectordb-consumer`:
   - **Principal**: Service account `sa-xxxxx`
   - **Permission**: Read
   - **Resource**: Topic `aura360.context.aggregated`
   - **Pattern**: Literal
4. Repetir para cada servicio con permisos mÃ­nimos necesarios

**Recomendado para producciÃ³n**:
- Django API: Write a `user.events`
- Vectordb: Read de `user.events`, Write a `context.*`
- Agents: Read de `guardian.requests`, Write a `guardian.responses`

### 5.2 Service Accounts

1. En **Accounts** tab â†’ **+ Add service account**
2. Crear cuentas separadas para cada servicio:
   - `aura360-api-producer`
   - `aura360-vectordb-consumer`
   - `aura360-agents-consumer`
3. Generar API Keys especÃ­ficas para cada cuenta
4. Aplicar ACLs como en 5.1

---

## ðŸ“Š Parte 6: Configurar Monitoring (Opcional pero Recomendado)

### 6.1 Habilitar Metrics

1. En el cluster, click **Metrics** tab
2. Configurar alertas:
   - **Consumer lag** > 1000 mensajes â†’ Email
   - **Produce error rate** > 1% â†’ Email
   - **Cluster health** â‰  Green â†’ Email

### 6.2 IntegraciÃ³n con Railway (ProducciÃ³n)

1. Copiar **Cluster ID** del dashboard
2. Configurar en Railway:
   ```bash
   KAFKA_CLUSTER_ID=lkc-xxxxx
   ```
3. Ver logs combinados en Railway + Confluent Cloud

---

## âœ… VerificaciÃ³n Final

### Checklist de VerificaciÃ³n

- [ ] Cuenta de Confluent Cloud creada y verificada
- [ ] Beneficio de 1 aÃ±o activado (o crÃ©ditos de free trial)
- [ ] Environment `aura360-prod` creado
- [ ] Cluster `aura360-kafka-prod` en estado **Ready**
- [ ] 6 topics creados con configuraciÃ³n correcta:
  - [ ] `aura360.user.events`
  - [ ] `aura360.context.aggregated`
  - [ ] `aura360.context.vectorized`
  - [ ] `aura360.guardian.requests`
  - [ ] `aura360.guardian.responses`
  - [ ] `aura360.vectordb.ingest`
- [ ] API Key del cluster generada y guardada seguramente
- [ ] Bootstrap Servers URL copiada
- [ ] (Opcional) Cloud API Key para MCP generada
- [ ] (Opcional) Schema Registry configurado
- [ ] (Opcional) ACLs y Service Accounts configurados
- [ ] (Opcional) Alertas configuradas

---

## ðŸ§ª Test de Conectividad

### OpciÃ³n A: Usando Confluent Cloud Console

1. En un topic, click **Messages** tab
2. Click **Produce a new message**
3. JSON:
   ```json
   {
     "test": "Hello from AURA360",
     "timestamp": "2025-01-07T12:00:00Z"
   }
   ```
4. Click **Produce**
5. âœ… DeberÃ­as ver el mensaje en la tabla

### OpciÃ³n B: Usando Python (desde tu mÃ¡quina)

```bash
# Crear test script
cat > /tmp/test_confluent.py <<'EOF'
from confluent_kafka import Producer
import json

# ConfiguraciÃ³n (reemplazar con tus valores)
conf = {
    'bootstrap.servers': 'pkc-xxxxx.us-east-1.aws.confluent.cloud:9092',
    'security.protocol': 'SASL_SSL',
    'sasl.mechanisms': 'PLAIN',
    'sasl.username': 'TU_API_KEY',
    'sasl.password': 'TU_API_SECRET',
}

producer = Producer(conf)

def delivery_report(err, msg):
    if err:
        print(f'âŒ Error: {err}')
    else:
        print(f'âœ… Message delivered to {msg.topic()} [{msg.partition()}]')

# Enviar mensaje de prueba
topic = 'aura360.user.events'
message = json.dumps({'test': 'Hello from AURA360', 'timestamp': '2025-01-07T12:00:00Z'})
producer.produce(topic, value=message, callback=delivery_report)
producer.flush()
EOF

# Instalar confluent-kafka
pip install confluent-kafka

# Ejecutar test
python /tmp/test_confluent.py
```

**Salida esperada**:
```
âœ… Message delivered to aura360.user.events [0]
```

---

## ðŸŽ¯ Siguiente Paso

Una vez completada esta guÃ­a:

1. **Copiar credenciales a `.env` files**:
   - `/services/api/.env`
   - `/services/vectordb/.env`
   - `/services/agents/.env`

2. **Configurar secrets en Railway**:
   ```bash
   railway variables set KAFKA_BOOTSTRAP_SERVERS="pkc-xxxxx.us-east-1.aws.confluent.cloud:9092"
   railway variables set KAFKA_API_KEY="tu-api-key"
   railway variables set KAFKA_API_SECRET="tu-api-secret"
   ```

3. **Continuar con MCP_CONFLUENT_SETUP.md** para integrar con Claude Desktop

---

## ðŸ’° EstimaciÃ³n de Costos (Post AÃ±o Gratis)

### Cluster Basic (us-east-1)
- **Costo base**: ~$150/mes
- **Ingestion**: $0.10/GB
- **Storage**: $0.10/GB/mes
- **Egress**: $0.05/GB

### Ejemplo para AURA360 (estimado)
- **TrÃ¡fico**: 100 GB/mes ingestion + 50 GB egress = $15
- **Storage**: 50 GB promedio = $5
- **Total**: ~$170/mes

**RecomendaciÃ³n**: En mes 10 del beneficio, evaluar migrar a self-hosted Kafka en Railway si el costo es prohibitivo.

---

## âš ï¸ Troubleshooting

### Error: "Invalid API Key"

```bash
# Verificar que estÃ©s usando:
# - API Key del CLUSTER (no Cloud API Key)
# - SASL_SSL protocol
# - PLAIN mechanism
```

### Error: "Topic not found"

```bash
# Verificar nombre exacto del topic (case-sensitive)
# Debe ser: aura360.user.events (no aura360_user_events)
```

### Error: "Authentication failed"

```bash
# Regenerar API Key en Confluent Cloud
# Asegurarte de copiar el Secret completo (sin espacios extras)
```

---

## ðŸ“š Recursos

- **Confluent Cloud Docs**: https://docs.confluent.io/cloud/current/
- **Free Trial**: https://www.confluent.io/confluent-cloud/tryfree/
- **Python Client**: https://docs.confluent.io/kafka-clients/python/current/
- **Best Practices**: https://docs.confluent.io/cloud/current/client-apps/best-practices.html

---

**ðŸŽ‰ Â¡Listo! Confluent Cloud estÃ¡ configurado y listo para usar.**

**PrÃ³ximos pasos**:
1. Ver `MCP_CONFLUENT_SETUP.md` para Claude Desktop
2. Ver `QUICKSTART_KAFKA.md` para comenzar a desarrollar
3. Actualizar `.env` files con las credenciales

---

**Ãšltima actualizaciÃ³n**: 2025-01-07
**VersiÃ³n**: 1.0
**Contacto**: DevOps Team
